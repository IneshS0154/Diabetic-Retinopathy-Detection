# -*- coding: utf-8 -*-
"""DR_02v1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1byWfcP9ycRFMXaYAl6VT4Ho9HEv5gqOx
"""

!pip install torch torchvision torchaudio gradio albumentations opencv-python-headless

from google.colab import drive
drive.mount('/content/drive')

import json

# Data to write
kaggle_credentials = {
    "username": "ineshs21",
    "key": "19640032a6e57339898f473e2087f918"
}

# Write to kaggle.json
with open("kaggle.json", "w") as json_file:
    json.dump(kaggle_credentials, json_file, indent=4)

print("kaggle.json file created successfully.")

import os
import zipfile

# Create the kaggle directory
os.makedirs('/root/.kaggle', exist_ok=True)

# Move kaggle.json into the directory
!mv kaggle.json /root/.kaggle/

# Set permissions
!chmod 600 /root/.kaggle/kaggle.json

#dataset download
!kaggle datasets download -d ascanipek/eyepacs-aptos-messidor-diabetic-retinopathy

!mkdir Dataset
!unzip eyepacs-aptos-messidor-diabetic-retinopathy.zip -d /content/Dataset

!mkdir Train/augmented_resized_V2
!ls

base_dir = '/content/Dataset/augmented_resized_V2'

print("Base directory exists:", os.path.exists(base_dir))

# 1. Data Collection
# The dataset is pre-organized under /content/Dataset/augmented_resized_V2 with train, val, and test subfolders, each containing 0, 1, 2, 3, 4 (DR stages).

# Action: Upload and extract as above. No CSV needed since labels are folder-based.
# Paths:

import os

base_dir = '/content/Dataset/augmented_resized_V2'  # Updated base directory
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')
test_dir = os.path.join(base_dir, 'test')
print(os.listdir(train_dir))  # Should show [0, 1, 2, 3, 4]

# 2. Data Pre-processing
# Prepare the dataset for training, using train for training, val for validation, and test for testing.

# Import necessary libraries
from torchvision import transforms

# --- Data Pre-processing Steps ---

# 1: Resizing and Cropping
# Resize to a larger size before cropping to a fixed input size (224x224).
# For training, a random crop is used. For validation/testing, a center crop is applied.

# 2: Augmentation for Robustness (Training Only)
# These transformations help the model generalize better and prevent overfitting.
# We add more variety to the training data with random rotations, flips, and color changes.
# The original code already included RandomHorizontalFlip and RandomRotation.

# 3: Conversion to Tensor
# This is a mandatory step that converts images into a PyTorch tensor format
# and scales pixel values from [0, 255] to [0.0, 1.0].

# 4: Normalization
# Standardizes the pixel values across all images using the mean and standard deviation
# from the ImageNet dataset. This is crucial for models using pre-trained weights.

# 5: Handling Class Imbalance (Implemented in DataLoader)
# This step is handled in the DataLoader setup using WeightedRandomSampler.
# It ensures that images from underrepresented classes (like severe DR stages)
# are sampled more frequently during training to prevent model bias.


train_transform = transforms.Compose([
    transforms.Resize(256),  # Step 1: Resize images
    transforms.RandomCrop(224), # Step 1: Randomly crop to final size (224Ã—224) to add randomness
    transforms.RandomHorizontalFlip(p=0.5), # Step 2: Augmentation - flips horizontally with prob = 0.5
    transforms.RandomVerticalFlip(p=0.5), # Step 2: Augmentation - flips vertically with prob = 0.5
    transforms.RandomApply([transforms.RandomRotation(degrees=15)], p=0.5), # Step 2: Augmentation - rotates upto +15 or -15 to add randomness
    transforms.ToTensor(), # Step 3: Convert to tensor & scales values to 0 - 1
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Step 4: Normalize - standardizes colors to match ImageNet pretraining stats
])

# Define transforms for the validation and test datasets
val_test_transform = transforms.Compose([
    transforms.Resize(256), # Step 1: Resize images
    transforms.CenterCrop(224), # Step 1: Center crop to final size
    transforms.ToTensor(), # Step 3: Convert to tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Step 4: Normalize
])

# Load Datasets:
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torch.utils.data.sampler import WeightedRandomSampler
import numpy as np

base_dir = '/content/Dataset/augmented_resized_V2'
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')
test_dir = os.path.join(base_dir, 'test')

train_dataset = ImageFolder(train_dir, transform=train_transform)
val_dataset = ImageFolder(val_dir, transform=val_test_transform)
test_dataset = ImageFolder(test_dir, transform=val_test_transform)


print(f"Train dataset classes: {train_dataset.classes}")
print(f"Dataset sizes: Train ({len(train_dataset)}), Val ({len(val_dataset)}), Test ({len(test_dataset)})")

# Class Imbalance (WeightedRandomSampler)
class_counts = np.bincount([label for _, label in train_dataset]) # how many images per class
print(f"Class counts: {class_counts}")

class_weights = 1. / class_counts # invert
sample_weights = [class_weights[label] for _, label in train_dataset] # give a weight for each sample
sampler = WeightedRandomSampler(sample_weights, len(sample_weights)) # sample more often from rare classes

train_loader = DataLoader(
    train_dataset,
    batch_size=512,      # try 512 first, maybe 1024 if it fits
    sampler=sampler,
    num_workers=8,
    pin_memory=True,
    prefetch_factor=4
)

val_loader = DataLoader(
    val_dataset,
    batch_size=512,      # bigger is fine (no gradients)
    shuffle=False,
    num_workers=4,
    pin_memory=True
)

test_loader = DataLoader(
    test_dataset,
    batch_size=512,      # bigger is fine (no gradients)
    shuffle=False,
    num_workers=4,
    pin_memory=True
)

# 4. Model Definition
import torch.nn as nn
import torch
from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights

model = efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 5)
device = torch.device('cuda')
model = model.to(device, memory_format=torch.channels_last)

# Training Components
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
# Corrected import for autocast and GradScaler
from torch.amp import autocast, GradScaler
import tqdm
import gc

# Hyperparameters
num_epochs = 30
learning_rate = 1e-4
accumulation_steps = 2

# Training components
class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)
criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)
optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1)
scaler = GradScaler()
best_val_loss = float('inf')
train_losses, val_losses = [], []

print("Starting training...")
for epoch in range(num_epochs):
    model.train()
    train_loss = 0
    torch.cuda.empty_cache()
    gc.collect()
    optimizer.zero_grad()

    for i, (inputs, labels) in enumerate(tqdm.tqdm(train_loader, desc=f"Epoch {epoch+1} Training")):
        inputs = inputs.to(device, non_blocking=True, memory_format=torch.channels_last)
        labels = labels.to(device, non_blocking=True)

        with autocast(device_type='cuda', dtype=torch.float16):
            outputs = model(inputs)
            loss = criterion(outputs, labels)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        optimizer.zero_grad()

        train_loss += loss.item() * inputs.size(0)


    # Validation Phase
    model.eval()
    val_loss = 0
    val_preds, val_trues = [], []
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            with autocast(device_type='cuda', dtype=torch.float16): # Corrected line
                outputs = model(inputs)
                val_loss += criterion(outputs, labels).item() * inputs.size(0)

            val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())
            val_trues.extend(labels.cpu().numpy())

    train_loss /= len(train_dataset)
    val_loss /= len(val_dataset)
    scheduler.step(val_loss)
    train_losses.append(train_loss)
    val_losses.append(val_loss)

    print(f'Epoch {epoch+1}: Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}')

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        torch.save(model.state_dict(), '/content/drive/MyDrive/best_dr_model.pth')

# 6. Model Evaluation
from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Load the best model
model.load_state_dict(torch.load('/content/drive/MyDrive/best_dr_model.pth'))
model.eval()

test_preds, test_trues = [], []
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs = inputs.to(device)
        outputs = model(inputs)
        test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())
        test_trues.extend(labels.cpu().numpy())

# Calculate metrics
acc = accuracy_score(test_trues, test_preds)
kappa = cohen_kappa_score(test_trues, test_preds, weights='quadratic')
print(f'Test Accuracy: {acc:.4f}, Quadratic Kappa: {kappa:.4f}')

# Plotting
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.figure(figsize=(8, 6))
cm = confusion_matrix(test_trues, test_preds)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)
plt.title('Confusion Matrix (Test Set)')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# Model Evaluation with Precision, Recall, and F1-Score
from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming you've already loaded the best model and made predictions on the test set:
# model.load_state_dict(torch.load('/content/drive/MyDrive/best_dr_model.pth'))
# model.eval()
# ... (prediction loop to get test_trues and test_preds)

# --- Calculate and print metrics ---

# Accuracy Score
acc = accuracy_score(test_trues, test_preds)
# Cohen's Kappa Score (Quadratic)
kappa = cohen_kappa_score(test_trues, test_preds, weights='quadratic')

print(f'Test Accuracy: {acc:.4f}')
print(f'Quadratic Kappa: {kappa:.4f}')

# Precision, Recall, and F1-Score
# The classification_report provides these metrics for each class.
print("\nClassification Report:")
print(classification_report(test_trues, test_preds, target_names=train_dataset.classes))

# --- Plotting ---

# Plotting the Confusion Matrix
plt.figure(figsize=(8, 6))
cm = confusion_matrix(test_trues, test_preds)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)
plt.title('Confusion Matrix (Test Set)')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()